{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac29ed50-2cbd-4b1e-ae65-e2a898a7612c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/notebook\n",
      "Cloning into 'MiniGPT-4'...\n",
      "remote: Enumerating objects: 289, done.\u001b[K\n",
      "remote: Counting objects: 100% (220/220), done.\u001b[K\n",
      "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
      "remote: Total 289 (delta 119), reused 105 (delta 105), pack-reused 69\u001b[K\n",
      "Receiving objects: 100% (289/289), 45.35 MiB | 9.19 MiB/s, done.\n",
      "Resolving deltas: 100% (127/127), done.\n"
     ]
    }
   ],
   "source": [
    "# 初回のみ\n",
    "%cd /app/notebook/\n",
    "!git clone https://github.com/Vision-CAIR/MiniGPT-4.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b54bf52-3f9c-4d88-bf73-ef303826d2d4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/notebook/MiniGPT-4\n",
      "Note: switching to '22d8888'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at 22d8888 Update README.md\n",
      "--2023-08-01 02:07:40--  https://huggingface.co/rinna/bilingual-gpt-neox-4b-minigpt4/resolve/main/customized_mini_gpt4.py\n",
      "Resolving huggingface.co (huggingface.co)... 18.172.52.106, 18.172.52.38, 18.172.52.61, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.172.52.106|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5964 (5.8K) [text/plain]\n",
      "Saving to: ‘customized_mini_gpt4.py’\n",
      "\n",
      "customized_mini_gpt 100%[===================>]   5.82K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-08-01 02:07:40 (4.11 GB/s) - ‘customized_mini_gpt4.py’ saved [5964/5964]\n",
      "\n",
      "--2023-08-01 02:07:40--  https://huggingface.co/rinna/bilingual-gpt-neox-4b-minigpt4/resolve/main/checkpoint.pth\n",
      "Resolving huggingface.co (huggingface.co)... 18.172.52.61, 18.172.52.106, 18.172.52.38, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.172.52.61|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/ec/45/ec45f64949f7ef83d659f021699d38453060bf136e279212fbf1b4801ce371c7/170633d5fd203d8b5b4d6d5ca3e3ce5bc8bb6cf66671ee96c0a6f4a1e38197e6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27checkpoint.pth%3B+filename%3D%22checkpoint.pth%22%3B&Expires=1691114861&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MTExNDg2MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy80NS9lYzQ1ZjY0OTQ5ZjdlZjgzZDY1OWYwMjE2OTlkMzg0NTMwNjBiZjEzNmUyNzkyMTJmYmYxYjQ4MDFjZTM3MWM3LzE3MDYzM2Q1ZmQyMDNkOGI1YjRkNmQ1Y2EzZTNjZTViYzhiYjZjZjY2NjcxZWU5NmMwYTZmNGExZTM4MTk3ZTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=Iy2FmhQmJiXFOx7TB6qI4sFN98tVv6JEh%7EKHNYQT74gM-9BSKjbKdfOARM1ZJLmOD0bAgpKxtYfWEp-phiZdukCm1bFiyhCaBpjRKq1FNBDMDyynU22aMHDT1TZYzEwFXl2LwGGQ7b%7E0JlYzIUo2D6phvsrZIWK0Zq3jAS7yOYNi308MxF-b48qwb6uuRW5zfcSayaLt2qa0auEZV2rBcMQkPRXuDWjcffFmhsgYQ2GQBI0CFve0VwoFCqWflcDhkunbezdaGQhSEAtGiuGvipU-MhJxSMDYPGwVtNhEj%7Elu4nN3ap8obrWabz3RSrWtBD0Guc0XUBIZKCKcfInLsQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-08-01 02:07:41--  https://cdn-lfs.huggingface.co/repos/ec/45/ec45f64949f7ef83d659f021699d38453060bf136e279212fbf1b4801ce371c7/170633d5fd203d8b5b4d6d5ca3e3ce5bc8bb6cf66671ee96c0a6f4a1e38197e6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27checkpoint.pth%3B+filename%3D%22checkpoint.pth%22%3B&Expires=1691114861&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MTExNDg2MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy80NS9lYzQ1ZjY0OTQ5ZjdlZjgzZDY1OWYwMjE2OTlkMzg0NTMwNjBiZjEzNmUyNzkyMTJmYmYxYjQ4MDFjZTM3MWM3LzE3MDYzM2Q1ZmQyMDNkOGI1YjRkNmQ1Y2EzZTNjZTViYzhiYjZjZjY2NjcxZWU5NmMwYTZmNGExZTM4MTk3ZTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=Iy2FmhQmJiXFOx7TB6qI4sFN98tVv6JEh%7EKHNYQT74gM-9BSKjbKdfOARM1ZJLmOD0bAgpKxtYfWEp-phiZdukCm1bFiyhCaBpjRKq1FNBDMDyynU22aMHDT1TZYzEwFXl2LwGGQ7b%7E0JlYzIUo2D6phvsrZIWK0Zq3jAS7yOYNi308MxF-b48qwb6uuRW5zfcSayaLt2qa0auEZV2rBcMQkPRXuDWjcffFmhsgYQ2GQBI0CFve0VwoFCqWflcDhkunbezdaGQhSEAtGiuGvipU-MhJxSMDYPGwVtNhEj%7Elu4nN3ap8obrWabz3RSrWtBD0Guc0XUBIZKCKcfInLsQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.172.31.69, 18.172.31.113, 18.172.31.71, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.172.31.69|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 177115114 (169M) [binary/octet-stream]\n",
      "Saving to: ‘checkpoint.pth’\n",
      "\n",
      "checkpoint.pth      100%[===================>] 168.91M  46.9MB/s    in 3.6s    \n",
      "\n",
      "2023-08-01 02:07:44 (46.7 MB/s) - ‘checkpoint.pth’ saved [177115114/177115114]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 初回のみ\n",
    "%cd /app/notebook/MiniGPT-4\n",
    "!git checkout 22d8888 # latest version as of July 31, 2023.\n",
    "!wget https://huggingface.co/rinna/bilingual-gpt-neox-4b-minigpt4/resolve/main/customized_mini_gpt4.py\n",
    "!wget https://huggingface.co/rinna/bilingual-gpt-neox-4b-minigpt4/resolve/main/checkpoint.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1ea5f3-3aa5-42a1-8f0c-c62d06e4c10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/app/notebook/MiniGPT-4'\n",
      "/app/notebook\n"
     ]
    }
   ],
   "source": [
    "# 次回以降はここから\n",
    "%cd /app/notebook/MiniGPT-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef0721a3-eef7-4c14-b510-933cce18415f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VIT\n",
      "freeze vision encoder\n",
      "Loading VIT Done\n",
      "Loading Q-Former\n",
      "freeze Qformer\n",
      "Loading Q-Former Done\n",
      "Loading LLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLM Done\n",
      "Load BLIP2-LLM Checkpoint: ./checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from minigpt4.processors.blip_processors import Blip2ImageEvalProcessor\n",
    "from customized_mini_gpt4 import CustomizedMiniGPT4\n",
    "\n",
    "ckpt_path = \"./checkpoint.pth\"\n",
    "\n",
    "model = CustomizedMiniGPT4(gpt_neox_model=\"rinna/bilingual-gpt-neox-4b\")\n",
    "tokenizer = model.gpt_neox_tokenizer\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "\n",
    "if ckpt_path is not None:\n",
    "    print(\"Load BLIP2-LLM Checkpoint: {}\".format(ckpt_path))\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(ckpt['model'], strict=False)\n",
    "\n",
    "vis_processor = Blip2ImageEvalProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba8d6d96-4e7b-43dd-a5c6-514865ccb55a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(image_url):\n",
    "    raw_image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
    "    image = vis_processor(raw_image).unsqueeze(0).to(model.device)\n",
    "    image_emb = model.encode_img(image)\n",
    "    prompt = [\n",
    "        {\n",
    "            \"speaker\": \"ユーザー\",\n",
    "            \"text\": \"<Img><ImageHere></Img> 何が見えますか？\"\n",
    "        },\n",
    "    ]\n",
    "    prompt = [\n",
    "        f\"{uttr['speaker']}: {uttr['text']}\"\n",
    "        for uttr in prompt\n",
    "    ]\n",
    "    prompt = \"\\n\".join(prompt)\n",
    "    prompt = (\n",
    "        prompt\n",
    "        + \"\\n\"\n",
    "        + \"システム: \"\n",
    "    )\n",
    "    print(prompt)\n",
    "\n",
    "    embs = model.get_context_emb(prompt, [image_emb])\n",
    "\n",
    "    output_ids = model.gpt_neox_model.generate(\n",
    "        inputs_embeds=embs,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=1.0,\n",
    "        top_p=0.85,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    output = tokenizer.decode(output_ids.tolist()[0], skip_special_tokens=True)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "627df11a-4f9d-446c-b934-afd74ba425f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ユーザー: <Img><ImageHere></Img> 何が見えますか？\n",
      "システム: \n",
      "絵\n"
     ]
    }
   ],
   "source": [
    "inference(\"https://ogre.natalie.mu/media/news/comic/2023/0325/jyuyutsu2_PV1_06.jpg?impolicy=hq&imwidth=730&imdensity=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae22eaaf-2cdd-4043-860a-ed9c285f377a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ユーザー: <Img><ImageHere></Img> 何が見えますか？\n",
      "システム: \n",
      "りんごです。\n"
     ]
    }
   ],
   "source": [
    "inference(\"https://upload.wikimedia.org/wikipedia/commons/1/15/Red_Apple.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "341548ac-2316-4c6d-a9b4-92849e0a3305",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "リンゴの断面\n"
     ]
    }
   ],
   "source": [
    "inference(\"https://img.cpcdn.com/recipes/4174680/640x480c/13c9ffb6dfb8c32eacda7b8b4628208c.jpg?u=11688791&p=1478826339\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0ecb1cab-5cce-488b-834b-2ae97fc2ed4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アニメキャラ、キャラクター、キャラ絵、アニメ、キャラ、漫画、キャラ絵\n"
     ]
    }
   ],
   "source": [
    "inference(\"https://collabo-cafe.com/wp-content/uploads/cadbb15fbe6e5c8c2878027820dfde30.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "79a48518-c040-4ab5-959a-dff7b5d864be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アニメの女の子\n"
     ]
    }
   ],
   "source": [
    "inference(\"https://static.mercdn.net/c!/w=240/thumb/photos/m55026016864_1.jpg?1689509667\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "38c35783-b021-4bdf-85cb-c8a758722f05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "洗濯機です。\n"
     ]
    }
   ],
   "source": [
    "inference(\"https://blog.ikehikoshop.jp/wp-content/uploads/2021/09/coin.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "acf5c172-154e-49bb-8275-4d98fcd4b0d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "黒い布が巻かれた手\n"
     ]
    }
   ],
   "source": [
    "inference(\"https://ogre.natalie.mu/media/news/comic/2022/1217/5_toji.jpg?imwidth=750&imdensity=1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
