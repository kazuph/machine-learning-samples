{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d906826-7eac-4c9d-b670-15d17231d875",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token $HUGGINGFACE_AUTH_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b765217d-afec-469e-a6f9-12b284df1a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ctranslate2 in /usr/local/lib/python3.10/dist-packages (3.18.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2) (1.24.1)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2) (6.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ctranslate2\n",
    "# !pip uninstall ctranslate2 -y\n",
    "# !pip install hf-hub-ctranslate2>=2.0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b7e09aa-e0c1-4240-bf19-f8f1f968d0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ct2-transformers-converter [-h] --model MODEL\n",
      "                                  [--activation_scales ACTIVATION_SCALES]\n",
      "                                  [--copy_files COPY_FILES [COPY_FILES ...]]\n",
      "                                  [--revision REVISION] [--low_cpu_mem_usage]\n",
      "                                  [--trust_remote_code] --output_dir\n",
      "                                  OUTPUT_DIR [--vocab_mapping VOCAB_MAPPING]\n",
      "                                  [--quantization {int8,int8_float32,int8_float16,int8_bfloat16,int16,float16,bfloat16,float32}]\n",
      "                                  [--force]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model MODEL         Name of the pretrained model to download, or path to a\n",
      "                        directory containing the pretrained model. (default:\n",
      "                        None)\n",
      "  --activation_scales ACTIVATION_SCALES\n",
      "                        Path to the pre-computed activation scales. Models may\n",
      "                        use them to rescale some weights to smooth the\n",
      "                        intermediate activations and improve the quantization\n",
      "                        accuracy. See https://github.com/mit-han-\n",
      "                        lab/smoothquant. (default: None)\n",
      "  --copy_files COPY_FILES [COPY_FILES ...]\n",
      "                        List of filenames to copy from the Hugging Face model\n",
      "                        to the converted model directory. (default: None)\n",
      "  --revision REVISION   Revision of the model to download from the Hugging\n",
      "                        Face Hub. (default: None)\n",
      "  --low_cpu_mem_usage   Enable the flag low_cpu_mem_usage when loading the\n",
      "                        model with from_pretrained. (default: False)\n",
      "  --trust_remote_code   Allow converting models using custom code. (default:\n",
      "                        False)\n",
      "  --output_dir OUTPUT_DIR\n",
      "                        Output model directory. (default: None)\n",
      "  --vocab_mapping VOCAB_MAPPING\n",
      "                        Vocabulary mapping file (optional). (default: None)\n",
      "  --quantization {int8,int8_float32,int8_float16,int8_bfloat16,int16,float16,bfloat16,float32}\n",
      "                        Weight quantization type. (default: None)\n",
      "  --force               Force conversion even if the output directory already\n",
      "                        exists. (default: False)\n"
     ]
    }
   ],
   "source": [
    "!ct2-transformers-converter --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2adac890-5214-4685-add1-1a76e65c6379",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/ct2-transformers-converter\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ctranslate2/converters/transformers.py\", line 1616, in main\n",
      "    converter.convert_from_args(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ctranslate2/converters/converter.py\", line 50, in convert_from_args\n",
      "    return self.convert(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ctranslate2/converters/converter.py\", line 89, in convert\n",
      "    model_spec = self._load()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ctranslate2/converters/transformers.py\", line 96, in _load\n",
      "    raise ValueError(\n",
      "ValueError: No conversion is registered for the model configuration JapaneseStableLMAlphaConfig (supported configurations are: BartConfig, BertConfig, BloomConfig, CodeGenConfig, GPT2Config, GPTBigCodeConfig, GPTJConfig, GPTNeoXConfig, LlamaConfig, M2M100Config, MBartConfig, MPTConfig, MT5Config, MarianConfig, OPTConfig, PegasusConfig, RWConfig, T5Config, WhisperConfig, XLMRobertaConfig)\n"
     ]
    }
   ],
   "source": [
    "!ct2-transformers-converter --model \"stabilityai/japanese-stablelm-instruct-alpha-7b\" --quantization int8 --output_dir stabilityai-jp-lm-7b_ct2_int8 --trust_remote_code --force"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
