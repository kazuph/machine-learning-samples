{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c198a74c-a0b3-401c-b8f3-cf6b5c549503",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "Cloning into 'vllm'...\n",
      "remote: Enumerating objects: 3334, done.\u001b[K\n",
      "remote: Counting objects: 100% (1171/1171), done.\u001b[K\n",
      "remote: Compressing objects: 100% (238/238), done.\u001b[K\n",
      "remote: Total 3334 (delta 1037), reused 941 (delta 933), pack-reused 2163\u001b[K\n",
      "Receiving objects: 100% (3334/3334), 4.19 MiB | 5.28 MiB/s, done.\n",
      "Resolving deltas: 100% (2269/2269), done.\n",
      "/vllm\n",
      "Processing /vllm\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (1.11.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (5.9.5)\n",
      "Requirement already satisfied: ray>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (2.7.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (2.1.0)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (13.0.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (0.1.99)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (1.24.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (2.0.1+cu118)\n",
      "Requirement already satisfied: transformers>=4.33.1 in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (4.33.2)\n",
      "Requirement already satisfied: xformers>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (0.0.21)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (0.103.1)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (0.23.2)\n",
      "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from vllm==0.1.7) (1.10.12)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2->vllm==0.1.7) (4.8.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.1.7) (8.1.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.1.7) (3.12.4)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.1.7) (4.19.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.1.7) (1.0.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.1.7) (23.1)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.1.7) (4.24.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.1.7) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.1.7) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.1.7) (1.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray>=2.5.1->vllm==0.1.7) (2.31.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->vllm==0.1.7) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->vllm==0.1.7) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->vllm==0.1.7) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->vllm==0.1.7) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.0->vllm==0.1.7) (3.27.5)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.0->vllm==0.1.7) (15.0.7)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.1->vllm==0.1.7) (0.17.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.1->vllm==0.1.7) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.1->vllm==0.1.7) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.1->vllm==0.1.7) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.1->vllm==0.1.7) (4.66.1)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->vllm==0.1.7) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->vllm==0.1.7) (0.27.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->vllm==0.1.7) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vllm==0.1.7) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vllm==0.1.7) (2023.3)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->vllm==0.1.7) (0.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm==0.1.7) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm==0.1.7) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm==0.1.7) (1.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers>=4.33.1->vllm==0.1.7) (2023.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->vllm==0.1.7) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->vllm==0.1.7) (2.1.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm==0.1.7) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm==0.1.7) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm==0.1.7) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.5.1->vllm==0.1.7) (0.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.5.1->vllm==0.1.7) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.5.1->vllm==0.1.7) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.5.1->vllm==0.1.7) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->vllm==0.1.7) (1.2.1)\n",
      "Building wheels for collected packages: vllm\n",
      "  Building wheel for vllm (pyproject.toml) ... \u001b[?25l-^C\n",
      "\u001b[?25canceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip3 uninstall -y vllm\n",
    "# !pip3 install autoawq\n",
    "# !git clone https://github.com/vllm-project/vllm.git\n",
    "# %cd vllm\n",
    "# !pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f09cc7-e50e-4e98-b6fb-8e61a93979d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  docker-compose.yml\trequirements.txt  test-awq.ipynb  vllm\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0499dde6-9fb9-49e4-8429-a2197a8f14c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-21 07:41:25 llm_engine.py:72] Initializing an LLM engine with config: model='TheBloke/Vicuna-13B-CoT-AWQ', tokenizer='TheBloke/Vicuna-13B-CoT-AWQ', tokenizer_mode=auto, revision=None, trust_remote_code=False, dtype=torch.float16, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=awq, seed=0)\n",
      "INFO 09-21 07:41:37 llm_engine.py:202] # GPU blocks: 1074, # CPU blocks: 327\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m52\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n",
      "INFO 09-21 07:42:46 async_llm_engine.py:371] Received request 396620f95b3141a3ac98742f079c1b88: prompt: '今日の天気は？', sampling params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, temperature=1.0, top_p=1.0, top_k=-1, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], ignore_eos=False, max_tokens=16, logprobs=None), prompt token ids: None.\n",
      "INFO 09-21 07:42:46 llm_engine.py:613] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%\n",
      "INFO 09-21 07:42:46 async_llm_engine.py:111] Finished request 396620f95b3141a3ac98742f079c1b88.\n",
      "\u001b[32mINFO\u001b[0m:     172.19.0.1:46202 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     172.19.0.1:33906 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[91m500 Internal Server Error\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 408, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/middleware/proxy_headers.py\", line 84, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/applications.py\", line 292, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/starlette/applications.py\", line 122, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 184, in __call__\n",
      "    raise exc\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 162, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/exceptions.py\", line 79, in __call__\n",
      "    raise exc\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/exceptions.py\", line 68, in __call__\n",
      "    await self.app(scope, receive, sender)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/middleware/asyncexitstack.py\", line 20, in __call__\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/middleware/asyncexitstack.py\", line 17, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 718, in __call__\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 276, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 66, in app\n",
      "    response = await func(request)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 273, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 190, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "  File \"/app/vllm/vllm/entrypoints/api_server.py\", line 32, in generate\n",
      "    sampling_params = SamplingParams(**request_dict)\n",
      "TypeError: SamplingParams.__init__() got an unexpected keyword argument 'max_token'\n",
      "INFO 09-21 07:43:10 async_llm_engine.py:371] Received request ab82694938d346b48eae74ce27a0f203: prompt: '今日の天気は？', sampling params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, temperature=1.0, top_p=1.0, top_k=-1, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], ignore_eos=False, max_tokens=256, logprobs=None), prompt token ids: None.\n",
      "INFO 09-21 07:43:11 llm_engine.py:613] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%\n",
      "INFO 09-21 07:43:14 async_llm_engine.py:111] Finished request ab82694938d346b48eae74ce27a0f203.\n",
      "\u001b[32mINFO\u001b[0m:     172.19.0.1:55226 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "INFO 09-21 07:43:31 async_llm_engine.py:371] Received request d876667ca17947cd9424426d71ad1c04: prompt: '今日の天気は？', sampling params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, temperature=1.0, top_p=1.0, top_k=-1, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], ignore_eos=False, max_tokens=256, logprobs=None), prompt token ids: None.\n",
      "INFO 09-21 07:43:31 llm_engine.py:613] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%\n",
      "INFO 09-21 07:43:35 async_llm_engine.py:111] Finished request d876667ca17947cd9424426d71ad1c04.\n",
      "\u001b[32mINFO\u001b[0m:     172.19.0.1:52124 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "INFO 09-21 07:46:02 async_llm_engine.py:371] Received request 13b1dc8e2f8b4dd7b4965b8fe708793d: prompt: '今日もいい天気ですね', sampling params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, temperature=1.0, top_p=1.0, top_k=-1, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], ignore_eos=False, max_tokens=256, logprobs=None), prompt token ids: None.\n",
      "INFO 09-21 07:46:02 llm_engine.py:613] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%\n",
      "INFO 09-21 07:46:06 async_llm_engine.py:111] Finished request 13b1dc8e2f8b4dd7b4965b8fe708793d.\n",
      "\u001b[32mINFO\u001b[0m:     172.19.0.1:53068 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "^C\n",
      "\u001b[32mINFO\u001b[0m:     Shutting down\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
      "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
      "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m52\u001b[0m]\n"
     ]
    }
   ],
   "source": [
    "!python3 -m vllm.entrypoints.api_server --host \"0.0.0.0\" --model TheBloke/Vicuna-13B-CoT-AWQ --quantization awq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df29381-18c8-467a-b9c9-4c3303798ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|█████| 687/687 [00:00<00:00, 6.48MB/s]\n",
      "INFO 09-21 08:14:43 llm_engine.py:72] Initializing an LLM engine with config: model='TheBloke/Nous-Hermes-13B-Code-AWQ', tokenizer='TheBloke/Nous-Hermes-13B-Code-AWQ', tokenizer_mode=auto, revision=None, trust_remote_code=False, dtype=torch.float16, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=awq, seed=0)\n",
      "Downloading (…)okenizer_config.json: 100%|█████| 732/732 [00:00<00:00, 8.80MB/s]\n",
      "Downloading tokenizer.model: 100%|████████████| 500k/500k [00:00<00:00, 767kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█| 1.84M/1.84M [00:01<00:00, 1.70MB/s]\n",
      "Downloading (…)in/added_tokens.json: 100%|████| 21.0/21.0 [00:00<00:00, 223kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|█████| 435/435 [00:00<00:00, 3.06MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████| 132/132 [00:00<00:00, 965kB/s]\n",
      "Downloading (…)1d/quant_config.json: 100%|████| 90.0/90.0 [00:00<00:00, 991kB/s]\n",
      "Downloading model.safetensors: 100%|███████| 7.25G/7.25G [05:07<00:00, 23.6MB/s]\n",
      "INFO 09-21 08:20:05 llm_engine.py:202] # GPU blocks: 1074, # CPU blocks: 327\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m161\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n",
      "^C\n",
      "\u001b[32mINFO\u001b[0m:     Shutting down\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
      "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
      "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m161\u001b[0m]\n"
     ]
    }
   ],
   "source": [
    "!python3 -m vllm.entrypoints.api_server --host \"0.0.0.0\" --model TheBloke/Nous-Hermes-13B-Code-AWQ --quantization awq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e81ed-12af-419b-b41d-cc070cb282b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|█████| 737/737 [00:00<00:00, 7.97MB/s]\n",
      "INFO 09-22 01:08:08 llm_engine.py:72] Initializing an LLM engine with config: model='TheBloke/WizardLM-13B-V1.1-AWQ', tokenizer='TheBloke/WizardLM-13B-V1.1-AWQ', tokenizer_mode=auto, revision=None, trust_remote_code=False, dtype=torch.float16, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=awq, seed=0)\n",
      "Downloading (…)okenizer_config.json: 100%|█████| 823/823 [00:00<00:00, 9.21MB/s]\n",
      "Downloading tokenizer.model: 100%|████████████| 500k/500k [00:00<00:00, 785kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█| 1.84M/1.84M [00:00<00:00, 5.35MB/s]\n",
      "Downloading (…)in/added_tokens.json: 100%|████| 21.0/21.0 [00:00<00:00, 152kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|█████| 435/435 [00:00<00:00, 3.13MB/s]\n",
      "Downloading (…)bb/quant_config.json: 100%|███| 90.0/90.0 [00:00<00:00, 1.10MB/s]\n",
      "Downloading (…)neration_config.json: 100%|█████| 132/132 [00:00<00:00, 1.02MB/s]\n",
      "Downloading model.safetensors: 100%|███████| 7.25G/7.25G [05:56<00:00, 20.3MB/s]\n",
      "INFO 09-22 01:14:19 llm_engine.py:202] # GPU blocks: 1074, # CPU blocks: 327\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m90\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n",
      "INFO 09-22 01:16:34 async_llm_engine.py:371] Received request 185c1941bf7a413994e50642560a4f8a: prompt: '今日もいい天気ですね', sampling params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, temperature=1.0, top_p=1.0, top_k=-1, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], ignore_eos=False, max_tokens=256, logprobs=None), prompt token ids: None.\n",
      "INFO 09-22 01:16:34 llm_engine.py:613] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%\n",
      "INFO 09-22 01:16:34 async_llm_engine.py:111] Finished request 185c1941bf7a413994e50642560a4f8a.\n",
      "\u001b[32mINFO\u001b[0m:     172.19.0.1:55962 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "INFO 09-22 01:16:36 async_llm_engine.py:371] Received request ee5e13dff9a94244bf7c287fb3cde64f: prompt: '今日もいい天気ですね', sampling params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, temperature=1.0, top_p=1.0, top_k=-1, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], ignore_eos=False, max_tokens=256, logprobs=None), prompt token ids: None.\n",
      "INFO 09-22 01:16:36 async_llm_engine.py:111] Finished request ee5e13dff9a94244bf7c287fb3cde64f.\n",
      "\u001b[32mINFO\u001b[0m:     172.19.0.1:55968 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "INFO 09-22 01:16:38 async_llm_engine.py:371] Received request 977471c6cb1c4e879590b486771334ed: prompt: '今日もいい天気ですね', sampling params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, temperature=1.0, top_p=1.0, top_k=-1, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], ignore_eos=False, max_tokens=256, logprobs=None), prompt token ids: None.\n",
      "INFO 09-22 01:16:38 async_llm_engine.py:111] Finished request 977471c6cb1c4e879590b486771334ed.\n",
      "\u001b[32mINFO\u001b[0m:     172.19.0.1:55972 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "INFO 09-22 01:16:39 async_llm_engine.py:371] Received request ed826318254e4011bea991f18ef0aef7: prompt: '今日もいい天気ですね', sampling params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, temperature=1.0, top_p=1.0, top_k=-1, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], ignore_eos=False, max_tokens=256, logprobs=None), prompt token ids: None.\n",
      "INFO 09-22 01:16:39 llm_engine.py:613] Avg prompt throughput: 8.5 tokens/s, Avg generation throughput: 1.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%\n",
      "INFO 09-22 01:16:39 async_llm_engine.py:111] Finished request ed826318254e4011bea991f18ef0aef7.\n",
      "\u001b[32mINFO\u001b[0m:     172.19.0.1:55978 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "INFO 09-22 01:16:40 async_llm_engine.py:371] Received request 3cfbc6f7ab21414cb6ac3554f795c377: prompt: '今日もいい天気ですね', sampling params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, temperature=1.0, top_p=1.0, top_k=-1, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], ignore_eos=False, max_tokens=256, logprobs=None), prompt token ids: None.\n",
      "INFO 09-22 01:16:44 async_llm_engine.py:111] Finished request 3cfbc6f7ab21414cb6ac3554f795c377.\n",
      "\u001b[32mINFO\u001b[0m:     172.19.0.1:38750 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "INFO 09-22 01:16:47 async_llm_engine.py:371] Received request db91bb6f37a34f1e96174b0c7a8c5ef4: prompt: '今日もいい天気ですね', sampling params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, temperature=1.0, top_p=1.0, top_k=-1, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], ignore_eos=False, max_tokens=256, logprobs=None), prompt token ids: None.\n",
      "INFO 09-22 01:16:47 llm_engine.py:613] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 25.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%\n",
      "INFO 09-22 01:16:49 async_llm_engine.py:111] Finished request db91bb6f37a34f1e96174b0c7a8c5ef4.\n",
      "\u001b[32mINFO\u001b[0m:     172.19.0.1:38752 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     172.19.0.1:64936 - \"\u001b[1mGET /generate HTTP/1.1\u001b[0m\" \u001b[31m405 Method Not Allowed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m vllm.entrypoints.api_server --host \"0.0.0.0\" --model TheBloke/WizardLM-13B-V1.1-AWQ --quantization awq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7a4162a-8f6e-47c3-b26c-88f225fada64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (269794396.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from \".\" import LLM, SamplingParams\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "prompts = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
    "\n",
    "llm = LLM(model=\"TheBloke/Vicuna-13B-CoT-AWQ\", quantization=\"awq\")\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "# Print the outputs.\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8db748a-c8ba-4d79-9862-b8fe7847f6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autoawq\n",
      "  Obtaining dependency information for autoawq from https://files.pythonhosted.org/packages/97/36/da85da021983420d9386d817fe28685248405bd222ac6fea76fe898a6b37/autoawq-0.0.2-cp310-cp310-manylinux2014_x86_64.whl.metadata\n",
      "  Using cached autoawq-0.0.2-cp310-cp310-manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from autoawq) (2.0.1+cu118)\n",
      "Requirement already satisfied: transformers>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from autoawq) (4.33.2)\n",
      "Requirement already satisfied: tokenizers>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from autoawq) (0.13.3)\n",
      "Collecting accelerate (from autoawq)\n",
      "  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/d9/92/2d3aecf9f4a192968035880be3e2fc8b48d541c7128f7c936f430d6f96da/accelerate-0.23.0-py3-none-any.whl.metadata\n",
      "  Using cached accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from autoawq) (0.1.99)\n",
      "Collecting lm-eval (from autoawq)\n",
      "  Using cached lm_eval-0.3.0-py3-none-any.whl (178 kB)\n",
      "Collecting texttable (from autoawq)\n",
      "  Using cached texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
      "Collecting toml (from autoawq)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting attributedict (from autoawq)\n",
      "  Using cached attributedict-0.3.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from autoawq) (4.24.3)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from autoawq) (0.15.2+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->autoawq) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->autoawq) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->autoawq) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->autoawq) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->autoawq) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->autoawq) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.0->autoawq) (3.27.5)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.0->autoawq) (15.0.7)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->autoawq) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->autoawq) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->autoawq) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->autoawq) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->autoawq) (2023.8.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->autoawq) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->autoawq) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.32.0->autoawq) (4.66.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->autoawq) (5.9.5)\n",
      "Collecting rootpath>=0.1.0 (from attributedict->autoawq)\n",
      "  Using cached rootpath-0.1.1-py3-none-any.whl (15 kB)\n",
      "Collecting inspecta>=0.1.0 (from attributedict->autoawq)\n",
      "  Using cached inspecta-0.1.3-py3-none-any.whl (9.2 kB)\n",
      "Collecting colour-runner>=0.0.5 (from attributedict->autoawq)\n",
      "  Using cached colour_runner-0.1.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Collecting deepdiff>=3.3.0 (from attributedict->autoawq)\n",
      "  Obtaining dependency information for deepdiff>=3.3.0 from https://files.pythonhosted.org/packages/0a/aa/ad75c66354a1b3619e73879a48219488e5ea91f26569d2f1fd4ba616cacd/deepdiff-6.5.0-py3-none-any.whl.metadata\n",
      "  Using cached deepdiff-6.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting tox>=3.0.0 (from attributedict->autoawq)\n",
      "  Obtaining dependency information for tox>=3.0.0 from https://files.pythonhosted.org/packages/f5/f9/963052e8b825645c54262dce7b7c88691505e3b9ee10a3e3667711eaaf21/tox-4.11.3-py3-none-any.whl.metadata\n",
      "  Using cached tox-4.11.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting coverage>=4.5.2 (from attributedict->autoawq)\n",
      "  Obtaining dependency information for coverage>=4.5.2 from https://files.pythonhosted.org/packages/13/6f/ebfba55e56aaf256dcae2b8e52a3ec3f1212a11a6d16cf9367d547a862b9/coverage-7.3.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached coverage-7.3.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting codecov>=2.0.15 (from attributedict->autoawq)\n",
      "  Using cached codecov-2.1.13-py2.py3-none-any.whl (16 kB)\n",
      "Collecting datasets>=2.0.0 (from lm-eval->autoawq)\n",
      "  Obtaining dependency information for datasets>=2.0.0 from https://files.pythonhosted.org/packages/09/7e/fd4d6441a541dba61d0acb3c1fd5df53214c2e9033854e837a99dd9e0793/datasets-2.14.5-py3-none-any.whl.metadata\n",
      "  Using cached datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting jsonlines (from lm-eval->autoawq)\n",
      "  Obtaining dependency information for jsonlines from https://files.pythonhosted.org/packages/f8/62/d9ba6323b9202dd2fe166beab8a86d29465c41a0288cbe229fac60c1ab8d/jsonlines-4.0.0-py3-none-any.whl.metadata\n",
      "  Using cached jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting numexpr (from lm-eval->autoawq)\n",
      "  Obtaining dependency information for numexpr from https://files.pythonhosted.org/packages/af/1f/a9bc507c4d53c0be52d2f1334dd79e13dc4663b64709b687a416506c2b86/numexpr-2.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached numexpr-2.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "Collecting openai>=0.6.4 (from lm-eval->autoawq)\n",
      "  Obtaining dependency information for openai>=0.6.4 from https://files.pythonhosted.org/packages/ae/59/911d6e5f1d7514d79c527067643376cddcf4cb8d1728e599b3b03ab51c69/openai-0.28.0-py3-none-any.whl.metadata\n",
      "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pybind11>=2.6.2 (from lm-eval->autoawq)\n",
      "  Obtaining dependency information for pybind11>=2.6.2 from https://files.pythonhosted.org/packages/06/55/9f73c32dda93fa4f539fafa268f9504e83c489f460c380371d94296126cd/pybind11-2.11.1-py3-none-any.whl.metadata\n",
      "  Using cached pybind11-2.11.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting pycountry (from lm-eval->autoawq)\n",
      "  Using cached pycountry-22.3.5-py2.py3-none-any.whl\n",
      "Collecting pytablewriter (from lm-eval->autoawq)\n",
      "  Obtaining dependency information for pytablewriter from https://files.pythonhosted.org/packages/3b/2b/065e66817ca41c19bae5b30232883dcc328ea4f1111d9158fc8987e2b7d8/pytablewriter-1.0.0-py3-none-any.whl.metadata\n",
      "  Using cached pytablewriter-1.0.0-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting rouge-score>=0.0.4 (from lm-eval->autoawq)\n",
      "  Using cached rouge_score-0.1.2-py3-none-any.whl\n",
      "Collecting sacrebleu==1.5.0 (from lm-eval->autoawq)\n",
      "  Using cached sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
      "Collecting scikit-learn>=0.24.1 (from lm-eval->autoawq)\n",
      "  Obtaining dependency information for scikit-learn>=0.24.1 from https://files.pythonhosted.org/packages/5c/e9/ee572691a3fb05555bcde41826faad29ae4bc1fb07982e7f53d54a176879/scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting sqlitedict (from lm-eval->autoawq)\n",
      "  Using cached sqlitedict-2.1.0-py3-none-any.whl\n",
      "Collecting tqdm-multiprocess (from lm-eval->autoawq)\n",
      "  Using cached tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
      "Collecting zstandard (from lm-eval->autoawq)\n",
      "  Using cached zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "Collecting portalocker (from sacrebleu==1.5.0->lm-eval->autoawq)\n",
      "  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->autoawq) (9.3.0)\n",
      "Collecting blessings (from colour-runner>=0.0.5->attributedict->autoawq)\n",
      "  Using cached blessings-1.7-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from colour-runner>=0.0.5->attributedict->autoawq) (2.16.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->lm-eval->autoawq) (13.0.0)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.0.0->lm-eval->autoawq)\n",
      "  Obtaining dependency information for dill<0.3.8,>=0.3.0 from https://files.pythonhosted.org/packages/f5/3a/74a29b11cf2cdfcd6ba89c0cecd70b37cd1ba7b77978ce611eb7a146a832/dill-0.3.7-py3-none-any.whl.metadata\n",
      "  Using cached dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->lm-eval->autoawq) (2.1.0)\n",
      "Collecting xxhash (from datasets>=2.0.0->lm-eval->autoawq)\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/13/c3/e942893f4864a424514c81640f114980cfd5aff7e7414d1e0255f4571111/xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets>=2.0.0->lm-eval->autoawq)\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/35/a8/36d8d7b3e46b377800d8dec47891cdf05842d1a2366909ae4a0c89fbc5e6/multiprocess-0.70.15-py310-none-any.whl.metadata\n",
      "  Using cached multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec[http]<2023.9.0,>=2023.1.0 (from datasets>=2.0.0->lm-eval->autoawq)\n",
      "  Obtaining dependency information for fsspec[http]<2023.9.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e3/bd/4c0a4619494188a9db5d77e2100ab7d544a42e76b2447869d8e124e981d8/fsspec-2023.6.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting aiohttp (from datasets>=2.0.0->lm-eval->autoawq)\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/3e/f6/fcda07dd1e72260989f0b22dde999ecfe80daa744f23ca167083683399bc/aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff>=3.3.0->attributedict->autoawq)\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers>=4.32.0->autoawq) (2023.9.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from inspecta>=0.1.0->attributedict->autoawq) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from inspecta>=0.1.0->attributedict->autoawq)\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.32.0->autoawq) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.32.0->autoawq) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.32.0->autoawq) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.32.0->autoawq) (2022.12.7)\n",
      "Collecting coloredlogs>=10.0 (from rootpath>=0.1.0->attributedict->autoawq)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting absl-py (from rouge-score>=0.0.4->lm-eval->autoawq)\n",
      "  Obtaining dependency information for absl-py from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting nltk (from rouge-score>=0.0.4->lm-eval->autoawq)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn>=0.24.1->lm-eval->autoawq)\n",
      "  Obtaining dependency information for scipy>=1.5.0 from https://files.pythonhosted.org/packages/a8/cc/c36f3439f5d47c3b13833ce6687b43a040cc7638c502ac46b41e2d4f3d6f/scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn>=0.24.1->lm-eval->autoawq)\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.24.1->lm-eval->autoawq)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting cachetools>=5.3.1 (from tox>=3.0.0->attributedict->autoawq)\n",
      "  Obtaining dependency information for cachetools>=5.3.1 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting chardet>=5.2 (from tox>=3.0.0->attributedict->autoawq)\n",
      "  Obtaining dependency information for chardet>=5.2 from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: colorama>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from tox>=3.0.0->attributedict->autoawq) (0.4.6)\n",
      "Collecting filelock (from torch>=2.0.0->autoawq)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/5e/5d/97afbafd9d584ff1b45fcb354a479a3609bd97f912f8f1f6c563cb1fae21/filelock-3.12.4-py3-none-any.whl.metadata\n",
      "  Using cached filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: platformdirs>=3.10 in /usr/local/lib/python3.10/dist-packages (from tox>=3.0.0->attributedict->autoawq) (3.10.0)\n",
      "Collecting pluggy>=1.3 (from tox>=3.0.0->attributedict->autoawq)\n",
      "  Obtaining dependency information for pluggy>=1.3 from https://files.pythonhosted.org/packages/05/b8/42ed91898d4784546c5f06c60506400548db3f7a4b3fb441cba4e5c17952/pluggy-1.3.0-py3-none-any.whl.metadata\n",
      "  Using cached pluggy-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pyproject-api>=1.6.1 (from tox>=3.0.0->attributedict->autoawq)\n",
      "  Obtaining dependency information for pyproject-api>=1.6.1 from https://files.pythonhosted.org/packages/cf/b4/39eea50542e50e93876ebc09c4349a9c9eee9f6b9c9d30f88c7dc5433db8/pyproject_api-1.6.1-py3-none-any.whl.metadata\n",
      "  Using cached pyproject_api-1.6.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from tox>=3.0.0->attributedict->autoawq) (2.0.1)\n",
      "Collecting virtualenv>=20.24.3 (from tox>=3.0.0->attributedict->autoawq)\n",
      "  Obtaining dependency information for virtualenv>=20.24.3 from https://files.pythonhosted.org/packages/4e/8b/f0d3a468c0186c603217a6656ea4f49259630e8ed99558501d92f6ff7dc3/virtualenv-20.24.5-py3-none-any.whl.metadata\n",
      "  Using cached virtualenv-20.24.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->autoawq) (2.1.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm-eval->autoawq) (23.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from pycountry->lm-eval->autoawq) (59.6.0)\n",
      "Collecting DataProperty<2,>=0.55.0 (from pytablewriter->lm-eval->autoawq)\n",
      "  Obtaining dependency information for DataProperty<2,>=0.55.0 from https://files.pythonhosted.org/packages/b1/3b/90ebd66ad57c588d6087e86e327436343e9cc60776a9445b79c6e80a022d/DataProperty-1.0.1-py3-none-any.whl.metadata\n",
      "  Using cached DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval->autoawq)\n",
      "  Obtaining dependency information for mbstrdecoder<2,>=1.0.0 from https://files.pythonhosted.org/packages/c2/0f/726229136022b154895138bb10ba35e8435c4143f614cb5ad4d4e3fc21ec/mbstrdecoder-1.1.3-py3-none-any.whl.metadata\n",
      "  Using cached mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval->autoawq)\n",
      "  Obtaining dependency information for pathvalidate<4,>=2.3.0 from https://files.pythonhosted.org/packages/0c/ab/673cce13ab635fd755d206b18c0a371ef6e28ddbe25fadba9ae6c59f22a5/pathvalidate-3.2.0-py3-none-any.whl.metadata\n",
      "  Using cached pathvalidate-3.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval->autoawq)\n",
      "  Obtaining dependency information for tabledata<2,>=1.3.1 from https://files.pythonhosted.org/packages/06/e2/96b10ebc00d20b55967200e3d95c2137d91f58af1af672627683431c9d5c/tabledata-1.3.3-py3-none-any.whl.metadata\n",
      "  Using cached tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval->autoawq)\n",
      "  Obtaining dependency information for tcolorpy<1,>=0.0.5 from https://files.pythonhosted.org/packages/34/d0/8a701df46bf546fd155da02934b0bb2ac6ad4186e29f4a3297e744ab259d/tcolorpy-0.1.4-py3-none-any.whl.metadata\n",
      "  Using cached tcolorpy-0.1.4-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting typepy[datetime]<2,>=1.2.0 (from pytablewriter->lm-eval->autoawq)\n",
      "  Obtaining dependency information for typepy[datetime]<2,>=1.2.0 from https://files.pythonhosted.org/packages/7f/31/0c7a66aa315cc8b2d1915fdd163283ba704307d7c0cf15b31e08c51aedba/typepy-1.3.1-py3-none-any.whl.metadata\n",
      "  Using cached typepy-1.3.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->autoawq) (1.2.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs>=10.0->rootpath>=0.1.0->attributedict->autoawq)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->lm-eval->autoawq)\n",
      "  Using cached multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets>=2.0.0->lm-eval->autoawq)\n",
      "  Obtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->lm-eval->autoawq)\n",
      "  Using cached yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.2.0->pytablewriter->lm-eval->autoawq) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.2.0->pytablewriter->lm-eval->autoawq) (2023.3.post1)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.24.3->tox>=3.0.0->attributedict->autoawq)\n",
      "  Obtaining dependency information for distlib<1,>=0.3.7 from https://files.pythonhosted.org/packages/43/a0/9ba967fdbd55293bacfc1507f58e316f740a3b231fc00e3d86dc39bc185a/distlib-0.3.7-py2.py3-none-any.whl.metadata\n",
      "  Using cached distlib-0.3.7-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.0.4->lm-eval->autoawq) (8.1.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.0.0->lm-eval->autoawq) (2023.3)\n",
      "Using cached autoawq-0.0.2-cp310-cp310-manylinux2014_x86_64.whl (3.4 MB)\n",
      "Using cached accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
      "Using cached coverage-7.3.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (229 kB)\n",
      "Using cached datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "Using cached deepdiff-6.5.0-py3-none-any.whl (71 kB)\n",
      "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
      "Using cached scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "Using cached tox-4.11.3-py3-none-any.whl (153 kB)\n",
      "Using cached filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Using cached jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Using cached numexpr-2.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (383 kB)\n",
      "Using cached pytablewriter-1.0.0-py3-none-any.whl (107 kB)\n",
      "Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
      "Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Using cached aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
      "Using cached pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
      "Using cached pluggy-1.3.0-py3-none-any.whl (18 kB)\n",
      "Using cached pyproject_api-1.6.1-py3-none-any.whl (12 kB)\n",
      "Using cached scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
      "Using cached tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
      "Using cached tcolorpy-0.1.4-py3-none-any.whl (7.9 kB)\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Using cached virtualenv-20.24.5-py3-none-any.whl (3.7 MB)\n",
      "Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Using cached multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Using cached xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached distlib-0.3.7-py2.py3-none-any.whl (468 kB)\n",
      "Using cached typepy-1.3.1-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: texttable, sqlitedict, distlib, zstandard, xxhash, tqdm-multiprocess, toml, threadpoolctl, termcolor, tcolorpy, scipy, pyproject-api, pycountry, pybind11, portalocker, pluggy, pathvalidate, ordered-set, numexpr, multidict, jsonlines, joblib, humanfriendly, fsspec, filelock, dill, coverage, chardet, cachetools, blessings, async-timeout, absl-py, yarl, virtualenv, scikit-learn, sacrebleu, nltk, multiprocess, mbstrdecoder, deepdiff, colour-runner, coloredlogs, codecov, typepy, tox, rouge-score, aiohttp, rootpath, openai, inspecta, datasets, DataProperty, tabledata, attributedict, pytablewriter, lm-eval, accelerate, autoawq\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.9.1\n",
      "    Uninstalling fsspec-2023.9.1:\n",
      "      Successfully uninstalled fsspec-2023.9.1\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.9.0\n",
      "    Uninstalling filelock-3.9.0:\n",
      "      Successfully uninstalled filelock-3.9.0\n",
      "Successfully installed DataProperty-1.0.1 absl-py-2.0.0 accelerate-0.23.0 aiohttp-3.8.5 async-timeout-4.0.3 attributedict-0.3.0 autoawq-0.0.2 blessings-1.7 cachetools-5.3.1 chardet-5.2.0 codecov-2.1.13 coloredlogs-15.0.1 colour-runner-0.1.1 coverage-7.3.1 datasets-2.14.5 deepdiff-6.5.0 dill-0.3.7 distlib-0.3.7 filelock-3.12.4 fsspec-2023.6.0 humanfriendly-10.0 inspecta-0.1.3 joblib-1.3.2 jsonlines-4.0.0 lm-eval-0.3.0 mbstrdecoder-1.1.3 multidict-6.0.4 multiprocess-0.70.15 nltk-3.8.1 numexpr-2.8.6 openai-0.28.0 ordered-set-4.1.0 pathvalidate-3.2.0 pluggy-1.3.0 portalocker-2.8.2 pybind11-2.11.1 pycountry-22.3.5 pyproject-api-1.6.1 pytablewriter-1.0.0 rootpath-0.1.1 rouge-score-0.1.2 sacrebleu-1.5.0 scikit-learn-1.3.0 scipy-1.11.2 sqlitedict-2.1.0 tabledata-1.3.3 tcolorpy-0.1.4 termcolor-2.3.0 texttable-1.6.7 threadpoolctl-3.2.0 toml-0.10.2 tox-4.11.3 tqdm-multiprocess-0.0.11 typepy-1.3.1 virtualenv-20.24.5 xxhash-3.3.0 yarl-1.9.2 zstandard-0.21.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install autoawq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f6c6fd-06df-4b13-8cca-b3e30dfc26fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AutoAWQForCausalLM.from_quantized() got an unexpected keyword argument 'safetensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model_name_or_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTheBloke/Vicuna-13B-CoT-AWQ\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoAWQForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_quantized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuse_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me about AI\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: AutoAWQForCausalLM.from_quantized() got an unexpected keyword argument 'safetensors'"
     ]
    }
   ],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name_or_path = \"TheBloke/Vicuna-13B-CoT-AWQ\"\n",
    "\n",
    "# Load model\n",
    "model = AutoAWQForCausalLM.from_quantized(model_name_or_path, fuse_layers=True,\n",
    "                                          trust_remote_code=False, safetensors=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=False)\n",
    "\n",
    "prompt = \"Tell me about AI\"\n",
    "prompt_template=f'''A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "tokens = tokenizer(\n",
    "    prompt_template,\n",
    "    return_tensors='pt'\n",
    ").input_ids.cuda()\n",
    "\n",
    "# Generate output\n",
    "generation_output = model.generate(\n",
    "    tokens,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "print(\"Output: \", tokenizer.decode(generation_output[0]))\n",
    "\n",
    "# Inference can also be done using transformers' pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"*** Pipeline:\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "print(pipe(prompt_template)[0]['generated_text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
